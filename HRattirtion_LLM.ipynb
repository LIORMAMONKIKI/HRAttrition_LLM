{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09a431c",
   "metadata": {},
   "source": [
    " # HR EMPLOYEE ATTIRITION LLM ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c906b",
   "metadata": {},
   "source": [
    "# HR Attrition Analysis: ML + LLM Integration\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Employee attrition is defined as the natural process by which employees leave the workforce (Yang & Islam, 2020). Employee turnover is regarded as a key issue for organizations due to its adverse effects on workplace productivity and accomplishing organizational objectives on time.\n",
    "\n",
    "### Technical Innovation\n",
    "This project demonstrates the integration of traditional Machine Learning models with Large Language Models (LLMs) to create human-readable, actionable insights from predictive analytics.\n",
    "\n",
    "### Objectives\n",
    "- Predict employee attrition using Random Forest and Logistic Regression\n",
    "- Generate personalized risk assessments using GPT-4\n",
    "- Create scalable framework for automated insight generation\n",
    "- Compare ML predictions with LLM explanations for strategic decision-making\n",
    "\n",
    "### Dataset\n",
    "- IBM HR Employee Attrition dataset\n",
    "- 1,470 employees, 36 attributes\n",
    "- Stratified sample of 249 employees for cost-effective LLM analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cccc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from openai import OpenAI\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database Configuration\n",
    "# Note: Replace with your actual database credentials\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'your_username',\n",
    "    'password': 'your_password', \n",
    "    'database': 'hrdb',\n",
    "    'use_pure': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established successfully\n",
      "Dataset loaded: 1470 employees, 36 features\n"
     ]
    }
   ],
   "source": [
    "# Database Connection\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"your_password\",  # Replace with actual credentials\n",
    "    database=\"hrdb\",\n",
    "    use_pure=True\n",
    ")\n",
    "\n",
    "print(\"Database connection established successfully\")\n",
    "\n",
    "# Data Extraction: Join employee demographics with employment details\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT * FROM table1 \n",
    "JOIN table2 ON table1.EmployeeNumber = table2.EmployeeNumber\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and create DataFrame\n",
    "mycursor = db.cursor()\n",
    "mycursor.execute(query)\n",
    "result = mycursor.fetchall()\n",
    "column_names = [i[0] for i in mycursor.description]\n",
    "df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} employees, {len(df.columns)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2e965c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset loaded: 1470 employees, 36 features\n",
      "Attrition rate: 16.1%\n"
     ]
    }
   ],
   "source": [
    "# Data Extraction: Employee Demographics + Employment Details\n",
    "# Dataset is normalized across two tables, requiring JOIN operation\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT * FROM table1 \n",
    "JOIN table2 ON table1.EmployeeNumber = table2.EmployeeNumber\n",
    "\"\"\"\n",
    "\n",
    "# Execute query and create DataFrame\n",
    "mycursor.execute(query)\n",
    "result = mycursor.fetchall()\n",
    "column_names = [i[0] for i in mycursor.description]\n",
    "df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "print(f\"Full dataset loaded: {len(df)} employees, {len(df.columns)} features\")\n",
    "print(f\"Attrition rate: {(df['Attrition'] == 'Yes').mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416bc7a",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Strategic Sampling\n",
    "\n",
    "### Business Context\n",
    "Employee attrition analysis combined with modern AI explanations to create actionable HR insights.\n",
    "\n",
    "### Technical Approach\n",
    "- Traditional ML models for accurate predictions\n",
    "- LLM integration for human-readable explanations\n",
    "- Cost-effective sampling strategy for API budget management\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bf40fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established\n",
      "Full dataset: 1470 employees, 36 features\n",
      "Overall attrition rate: 16.1%\n",
      "Sample size: 249 employees\n",
      "Sample attrition rate: 16.1%\n",
      "✓ Representative sample created for LLM analysis\n"
     ]
    }
   ],
   "source": [
    "# Database Connection\n",
    "db = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"KikiLili4ever$\",\n",
    "    database=\"hrdb\",\n",
    "    use_pure=True\n",
    ")\n",
    "\n",
    "print(\"Database connection established\")\n",
    "\n",
    "# Data Extraction: Join normalized tables\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT * FROM table1 \n",
    "JOIN table2 ON table1.EmployeeNumber = table2.EmployeeNumber\n",
    "\"\"\"\n",
    "\n",
    "mycursor = db.cursor()\n",
    "mycursor.execute(query)\n",
    "result = mycursor.fetchall()\n",
    "column_names = [i[0] for i in mycursor.description]\n",
    "df = pd.DataFrame(result, columns=column_names)\n",
    "\n",
    "# Dataset Overview\n",
    "print(f\"Full dataset: {len(df)} employees, {df.shape[1]} features\")\n",
    "print(f\"Overall attrition rate: {(df['Attrition'] == 'Yes').mean():.1%}\")\n",
    "\n",
    "# Strategic Sampling with Proper Department Representation\n",
    "# Each LLM analysis costs ~$0.02, so 249 employees ≈ $5 total\n",
    "\n",
    "# Create combined stratification variable (Department + Attrition)\n",
    "df['stratify_var'] = df['Department'] + '_' + df['Attrition']\n",
    "\n",
    "# Multi-variable stratified sampling\n",
    "sample_df, _ = train_test_split(\n",
    "    df,\n",
    "    test_size=0.83,\n",
    "    stratify=df['stratify_var'],  # Maintains both department AND attrition ratios\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Clean up temporary column\n",
    "sample_df = sample_df.drop('stratify_var', axis=1)\n",
    "df = df.drop('stratify_var', axis=1)\n",
    "\n",
    "print(f\"Sample size: {len(sample_df)} employees\")\n",
    "print(f\"Sample attrition rate: {(sample_df['Attrition'] == 'Yes').mean():.1%}\")\n",
    "print(\"✓ Representative sample created for LLM analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e1c75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Quality Check:\n",
      "Department Distribution Verification:\n",
      "Original → Sample:\n",
      "  Sales: 30.3% → 30.5%\n",
      "  Research & Development: 65.4% → 65.1%\n",
      "  Human Resources: 4.3% → 4.4%\n",
      "\n",
      "Department Attrition Rate Verification:\n",
      "Original → Sample:\n",
      "  Sales: 20.6% → 21.1%\n",
      "  Research & Development: 13.8% → 13.6%\n",
      "  Human Resources: 19.0% → 18.2%\n",
      "✓ Sample maintains original data distributions\n"
     ]
    }
   ],
   "source": [
    "# Sample Representativeness Validation\n",
    "print(\"\\nSample Quality Check:\")\n",
    "print(\"Department Distribution Verification:\")\n",
    "print(\"Original → Sample:\")\n",
    "for dept in df['Department'].unique():\n",
    "    orig_pct = (df['Department'] == dept).mean()\n",
    "    sample_pct = (sample_df['Department'] == dept).mean()\n",
    "    print(f\"  {dept}: {orig_pct:.1%} → {sample_pct:.1%}\")\n",
    "\n",
    "print(\"\\nDepartment Attrition Rate Verification:\")\n",
    "print(\"Original → Sample:\")\n",
    "for dept in df['Department'].unique():\n",
    "    orig_rate = (df[df['Department'] == dept]['Attrition'] == 'Yes').mean()\n",
    "    sample_rate = (sample_df[sample_df['Department'] == dept]['Attrition'] == 'Yes').mean()\n",
    "    print(f\"  {dept}: {orig_rate:.1%} → {sample_rate:.1%}\")\n",
    "\n",
    "print(\"✓ Sample maintains original data distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f7ae3",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Model Development\n",
    "\n",
    "Traditional ML models provide accurate attrition predictions that will be enhanced with LLM explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26fcddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns identified: 9 features\n",
      "Target encoding: No=0, Yes=1\n",
      "Encoded 8 categorical features\n"
     ]
    }
   ],
   "source": [
    "# ML Pipeline Setup\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Data Preprocessing\n",
    "ml_df = sample_df.copy()\n",
    "categorical_cols = ml_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns identified: {len(categorical_cols)} features\")\n",
    "\n",
    "# Encode categorical variables\n",
    "encoded_df = ml_df.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "# Target variable encoding\n",
    "le_target = LabelEncoder()\n",
    "encoded_df['Attrition'] = le_target.fit_transform(encoded_df['Attrition'])\n",
    "print(f\"Target encoding: No=0, Yes=1\")\n",
    "\n",
    "# Feature encoding\n",
    "for col in categorical_cols:\n",
    "    if col != 'Attrition':\n",
    "        le = LabelEncoder()\n",
    "        encoded_df[col] = le.fit_transform(encoded_df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(f\"Encoded {len(categorical_cols)-1} categorical features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bd9ada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature set: 27 features\n",
      "Removed irrelevant features: ['EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours', 'DailyRate', 'HourlyRate', 'MonthlyRate']\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering & Data Preparation\n",
    "encoded_df = ml_df.copy()\n",
    "\n",
    "# Target variable encoding\n",
    "le_target = LabelEncoder()\n",
    "encoded_df['Attrition'] = le_target.fit_transform(encoded_df['Attrition'])\n",
    "\n",
    "# Feature encoding\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col != 'Attrition':\n",
    "        le = LabelEncoder()\n",
    "        encoded_df[col] = le.fit_transform(encoded_df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Remove irrelevant features (following Yang & Islam methodology)\n",
    "irrelevant_features = ['EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours', \n",
    "                      'DailyRate', 'HourlyRate', 'MonthlyRate']\n",
    "features_to_remove = [col for col in irrelevant_features if col in encoded_df.columns]\n",
    "\n",
    "X = encoded_df.drop(['Attrition'] + features_to_remove, axis=1)\n",
    "y = encoded_df['Attrition']\n",
    "\n",
    "print(f\"Final feature set: {X.shape[1]} features\")\n",
    "print(f\"Removed irrelevant features: {features_to_remove}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2732670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 199 employees | Testing: 50 employees\n",
      "Random Forest Accuracy: 86.0%\n",
      "Logistic Regression Accuracy: 88.0%\n",
      "\n",
      "Top 5 Predictive Features:\n",
      "14. MonthlyIncome: 0.108\n",
      "21. TotalWorkingYears: 0.100\n",
      "4. DistanceFromHome: 0.076\n",
      "1. Age: 0.065\n",
      "16. OverTime: 0.059\n"
     ]
    }
   ],
   "source": [
    "# Model Training & Evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train ML Models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Model Performance\n",
    "rf_accuracy = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "lr_accuracy = accuracy_score(y_test, lr_model.predict(X_test))\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} employees | Testing: {X_test.shape[0]} employees\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.1%}\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.1%}\")\n",
    "\n",
    "# Feature Importance Analysis\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 Predictive Features:\")\n",
    "for i, row in importance_df.head(5).iterrows():\n",
    "    print(f\"{i+1}. {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67ae2e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Quality Check:\n",
      "Department Distribution:\n",
      "  Human Resources: 4.4%\n",
      "  Research & Development: 65.1%\n",
      "  Sales: 30.5%\n",
      "\n",
      "Job Level Distribution:\n",
      "  Level 1: 36.9%\n",
      "  Level 2: 32.5%\n",
      "  Level 3: 16.1%\n",
      "  Level 4: 6.8%\n",
      "  Level 5: 7.6%\n",
      "✓ Sample maintains original data distributions\n"
     ]
    }
   ],
   "source": [
    "# Sample Representativeness Validation\n",
    "print(\"Sample Quality Check:\")\n",
    "print(\"Department Distribution:\")\n",
    "dept_dist = sample_df['Department'].value_counts(normalize=True).sort_index()\n",
    "for dept, pct in dept_dist.items():\n",
    "    print(f\"  {dept}: {pct:.1%}\")\n",
    "\n",
    "print(\"\\nJob Level Distribution:\")\n",
    "job_dist = sample_df['JobLevel'].value_counts(normalize=True).sort_index() \n",
    "for level, pct in job_dist.items():\n",
    "    print(f\"  Level {level}: {pct:.1%}\")\n",
    "\n",
    "print(\"✓ Sample maintains original data distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d28f7f",
   "metadata": {},
   "source": [
    "## 3. LLM Integration for Actionable Insights\n",
    "\n",
    "Traditional ML provides accurate predictions but lacks human-readable explanations. We integrate GPT-4 to translate numerical predictions into strategic recommendations managers can understand and act upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d924cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GPT-4 connection...\n",
      "'GPT-4 connected successfully!'\n",
      "GPT-4 API connected successfully!\n"
     ]
    }
   ],
   "source": [
    "# Section 3: LLM Integration for Actionable Insights\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Initialize OpenAI client \n",
    "# Note: Replace with your actual API key\n",
    "api_key = \"your-openai-api-key-here\"  # Replace with actual key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Test connection\n",
    "print(\"Testing GPT-4 connection...\")\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say 'GPT-4 connected successfully!'\"}],\n",
    "        max_tokens=15\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"GPT-4 API connected successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"GPT-4 Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "851ca664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee risk assessment function ready\n"
     ]
    }
   ],
   "source": [
    "# Employee Risk Assessment Function (Enhanced)\n",
    "def explain_attrition_prediction(employee_data, ml_prediction, ml_probability):\n",
    "    \"\"\"\n",
    "    Generate human-readable explanations focusing on key predictive factors\n",
    "    \"\"\"\n",
    "    # Convert employee data (handle numpy types for JSON compatibility)\n",
    "    employee_info = {}\n",
    "    for i, feature in enumerate(X_paper.columns):\n",
    "        value = employee_data[i]\n",
    "        employee_info[feature] = value.item() if hasattr(value, 'item') else value\n",
    "    \n",
    "    # Focus on most predictive features from our analysis\n",
    "    key_features = {\n",
    "        'DistanceFromHome': employee_info.get('DistanceFromHome'),\n",
    "        'Age': employee_info.get('Age'), \n",
    "        'MonthlyIncome': employee_info.get('MonthlyIncome'),\n",
    "        'TotalWorkingYears': employee_info.get('TotalWorkingYears'),\n",
    "        'WorkLifeBalance': employee_info.get('WorkLifeBalance')\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert HR analyst. Analyze this employee's attrition risk:\n",
    "    \n",
    "    Key Predictive Factors: {key_features}\n",
    "    ML Prediction: {'Will likely leave' if ml_prediction == 1 else 'Will likely stay'}\n",
    "    Risk Probability: {ml_probability:.1%}\n",
    "    \n",
    "    Provide: 1) Analysis of key risk factors 2) Business rationale 3) Specific HR recommendations\n",
    "    Keep under 120 words, actionable for managers.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=180,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"Employee risk assessment function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1409e2",
   "metadata": {},
   "source": [
    "## 4. Individual Employee Risk Assessments\n",
    "\n",
    "Demonstrating personalized AI-powered insights that translate ML predictions into actionable HR recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c869971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYEE RISK ASSESSMENT EXAMPLE\n",
      "==================================================\n",
      "Actual Outcome: Stayed\n",
      "ML Prediction: Will stay\n",
      "Risk Probability: 5.0%\n",
      "\n",
      "AI-Generated Strategic Assessment:\n",
      "----------------------------------------\n",
      "1) The employee is at a low risk of attrition (5%), likely due to their age, reasonable commute, and balanced work-life situation. Their income and total working years also suggest stability.\n",
      "2) Retaining experienced employees is crucial for business continuity and knowledge retention.\n",
      "3) Recommendations: Maintain the employee's work-life balance and consider recognizing their experience and loyalty with a salary review or career development opportunities. Regular check-ins can also help to address any potential issues early.\n"
     ]
    }
   ],
   "source": [
    "# Generate Individual Risk Assessment\n",
    "print(\"EMPLOYEE RISK ASSESSMENT EXAMPLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Select sample employee from test set\n",
    "sample_employee = X_test_paper.iloc[0].values\n",
    "actual_outcome = y_test.iloc[0]\n",
    "\n",
    "# Generate ML prediction\n",
    "rf_prediction = rf_model.predict([sample_employee])[0]\n",
    "rf_probability = rf_model.predict_proba([sample_employee])[0][1]\n",
    "\n",
    "# Display prediction summary\n",
    "print(f\"Actual Outcome: {'Left' if actual_outcome == 1 else 'Stayed'}\")\n",
    "print(f\"ML Prediction: {'Will leave' if rf_prediction == 1 else 'Will stay'}\")\n",
    "print(f\"Risk Probability: {rf_probability:.1%}\")\n",
    "\n",
    "# Generate AI explanation\n",
    "print(f\"\\nAI-Generated Strategic Assessment:\")\n",
    "print(\"-\" * 40)\n",
    "explanation = explain_attrition_prediction(sample_employee, rf_prediction, rf_probability)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aee85c",
   "metadata": {},
   "source": [
    "## 5. Portfolio-Wide Risk Analysis\n",
    "\n",
    "Scaling individual predictions to organizational insights across all 249 employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91c3369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORGANIZATIONAL RISK PORTFOLIO\n",
      "========================================\n",
      "Total employees analyzed: 249\n",
      "High risk (>50%): 11 employees\n",
      "Medium risk (20-50%): 67 employees\n",
      "Low risk (<20%): 171 employees\n",
      "\n",
      "Key Pattern: High-risk employees average 30.5 years old\n",
      "vs Low-risk employees average 37.7 years old\n"
     ]
    }
   ],
   "source": [
    "# Generate Predictions for All Employees\n",
    "all_predictions = rf_model.predict(X_paper)\n",
    "all_probabilities = rf_model.predict_proba(X_paper)[:, 1]\n",
    "\n",
    "# Create comprehensive results dataset\n",
    "results_df = pd.DataFrame({\n",
    "    'employee_index': range(len(X_paper)),\n",
    "    'actual_outcome': y.values,\n",
    "    'predicted_outcome': all_predictions,\n",
    "    'leave_probability': all_probabilities\n",
    "})\n",
    "\n",
    "# Add key demographic features for analysis\n",
    "for feature in ['Age', 'DistanceFromHome', 'MonthlyIncome', 'TotalWorkingYears']:\n",
    "    if feature in X_paper.columns:\n",
    "        results_df[feature] = X_paper[feature].values\n",
    "\n",
    "# Risk Segmentation Analysis\n",
    "high_risk = results_df[results_df['leave_probability'] > 0.5]\n",
    "medium_risk = results_df[(results_df['leave_probability'] >= 0.2) & (results_df['leave_probability'] <= 0.5)]\n",
    "low_risk = results_df[results_df['leave_probability'] < 0.2]\n",
    "\n",
    "print(\"ORGANIZATIONAL RISK PORTFOLIO\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Total employees analyzed: {len(results_df)}\")\n",
    "print(f\"High risk (>50%): {len(high_risk)} employees\")\n",
    "print(f\"Medium risk (20-50%): {len(medium_risk)} employees\") \n",
    "print(f\"Low risk (<20%): {len(low_risk)} employees\")\n",
    "\n",
    "print(f\"\\nKey Pattern: High-risk employees average {high_risk['Age'].mean():.1f} years old\")\n",
    "print(f\"vs Low-risk employees average {low_risk['Age'].mean():.1f} years old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56d884",
   "metadata": {},
   "source": [
    "## 6. Executive Strategic Analysis\n",
    "\n",
    "Synthesizing individual predictions into actionable organizational insights using AI-powered analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d04964fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTIVE STRATEGIC ANALYSIS\n",
      "==================================================\n",
      "Executive Summary:\n",
      "\n",
      "Our HR analytics reveals that we currently have a total of 249 employees, with an overall attrition rate of 16.1%. The highest attrition rate is observed in the Sales department (21.1%), followed by Human Resources (18.2%), and Research & Development (13.6%). \n",
      "\n",
      "The top three attrition drivers appear to be departmental alignment, age, and a high-risk group of 11 employees. The age gap of 1.9 suggests a potential generational conflict or differing work styles that may be contributing to attrition. \n",
      "\n",
      "The highest-risk employee segments are in the Sales department, which also has the highest attrition rate. This suggests that interventions should be prioritized in this area. \n",
      "\n",
      "Department-specific patterns indicate that attrition rates vary significantly across departments. This suggests that department-specific interventions may be necessary, rather than a one-size-fits-all approach. \n",
      "\n",
      "To mitigate these issues, priority interventions could include implementing a mentorship program to bridge the age gap, enhancing departmental cohesion through team-building activities, and providing additional support and resources to high-risk employees. We expect these interventions to reduce attrition rates, improve employee satisfaction, and ultimately, increase productivity.\n"
     ]
    }
   ],
   "source": [
    "# Executive Analysis Function\n",
    "def generate_strategic_analysis():\n",
    "    \"\"\"\n",
    "    Generate comprehensive strategic insights from employee data patterns\n",
    "    \"\"\"\n",
    "    # Analyze key organizational patterns\n",
    "    feature_insights = {}\n",
    "    \n",
    "    # Department-level analysis\n",
    "    dept_analysis = sample_df.groupby('Department')['Attrition'].apply(\n",
    "        lambda x: (x == 'Yes').mean()\n",
    "    )\n",
    "    \n",
    "    # Risk factor comparison\n",
    "    leavers = sample_df[sample_df['Attrition'] == 'Yes']\n",
    "    stayers = sample_df[sample_df['Attrition'] == 'No']\n",
    "    \n",
    "    analysis_summary = {\n",
    "        'total_employees': len(sample_df),\n",
    "        'attrition_rate': f\"{(sample_df['Attrition'] == 'Yes').mean():.1%}\",\n",
    "        'high_risk_count': len(results_df[results_df['leave_probability'] > 0.5]),\n",
    "        'dept_rates': {dept: f\"{rate:.1%}\" for dept, rate in dept_analysis.items()},\n",
    "        'age_gap': round(stayers['Age'].mean() - leavers['Age'].mean(), 1)\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Executive HR Analytics Brief\n",
    "    \n",
    "    Analysis Summary: {json.dumps(analysis_summary, indent=2)}\n",
    "    \n",
    "    Provide strategic analysis:\n",
    "    1. Top 3 attrition drivers\n",
    "    2. Highest-risk employee segments  \n",
    "    3. Department-specific patterns\n",
    "    4. Priority interventions with expected impact\n",
    "    \n",
    "    Format as executive summary (250 words max).\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=350,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Generate Executive Analysis\n",
    "print(\"EXECUTIVE STRATEGIC ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "strategic_analysis = generate_strategic_analysis()\n",
    "print(strategic_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "329e6b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department Attrition Verification:\n",
      "Research & Development: 22/162 = 13.6%\n",
      "Sales: 16/76 = 21.1%\n",
      "Human Resources: 2/11 = 18.2%\n"
     ]
    }
   ],
   "source": [
    "# Verify department attrition rates\n",
    "print(\"Department Attrition Verification:\")\n",
    "for dept in sample_df['Department'].unique():\n",
    "    dept_data = sample_df[sample_df['Department'] == dept]\n",
    "    total = len(dept_data)\n",
    "    left = (dept_data['Attrition'] == 'Yes').sum()\n",
    "    rate = left / total\n",
    "    print(f\"{dept}: {left}/{total} = {rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ff32b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating strategic analysis...\n",
      "\n",
      "============================================================\n",
      "STRATEGIC ATTRITION ANALYSIS\n",
      "============================================================\n",
      "EXECUTIVE SUMMARY:\n",
      "\n",
      "The primary drivers of attrition appear to be age, distance from home, monthly income, total working years, business travel, and overtime. Younger employees, those living further from work, those with lower incomes, and those with fewer years of experience are more likely to leave. Additionally, frequent business travel and overtime work significantly increase attrition rates.\n",
      "\n",
      "High-risk employee segments include those who travel frequently for business (23.5% attrition), those working overtime (31.3% attrition), and Sales Representatives (35.7% attrition). \n",
      "\n",
      "In terms of department/role patterns, the Sales department has the highest attrition rate (21.1%), followed by Human Resources (18.2%). Within job roles, Sales Representatives and Laboratory Technicians have the highest attrition rates. \n",
      "\n",
      "Recommendations to reduce attrition include: \n",
      "\n",
      "1. Implement flexible work policies to accommodate employees living further from work. \n",
      "2. Review compensation packages, particularly for lower-income employees. \n",
      "3. Limit the frequency of business travel and overtime work. \n",
      "4. Provide career development opportunities to retain younger, less experienced employees. \n",
      "\n",
      "Specific interventions could include a company-wide survey to understand employee needs and concerns, a mentorship program for younger employees, and a review of job roles with high attrition rates to identify potential issues. Regular check-ins with employees who travel frequently or work overtime could also be beneficial.\n"
     ]
    }
   ],
   "source": [
    "# Fixed comprehensive analysis function\n",
    "def generate_strategic_attrition_analysis():\n",
    "    \"\"\"\n",
    "    Generate comprehensive strategic analysis using LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    # Work with the original sample data that has all features\n",
    "    leavers_mask = y == 1\n",
    "    stayers_mask = y == 0\n",
    "    \n",
    "    feature_analysis = {}\n",
    "    categorical_features = ['BusinessTravel', 'Department', 'JobRole', 'MaritalStatus', 'OverTime']\n",
    "    \n",
    "    # Analyze key features only (avoid overwhelming the LLM)\n",
    "    key_features = ['Age', 'DistanceFromHome', 'MonthlyIncome', 'TotalWorkingYears', \n",
    "                   'BusinessTravel', 'Department', 'JobRole', 'OverTime']\n",
    "    \n",
    "    for feature in key_features:\n",
    "        if feature in X_paper.columns:\n",
    "            if feature in categorical_features:\n",
    "                # For categorical: attrition rate by category\n",
    "                feature_data = sample_df[feature]\n",
    "                attrition_by_category = {}\n",
    "                for value in feature_data.unique():\n",
    "                    mask = feature_data == value\n",
    "                    if mask.sum() > 0:\n",
    "                        attrition_rate = y[mask].mean()\n",
    "                        count = mask.sum()\n",
    "                        attrition_by_category[str(value)] = f\"{attrition_rate:.1%} ({count} employees)\"\n",
    "                feature_analysis[feature] = attrition_by_category\n",
    "            else:\n",
    "                # For numerical: compare leavers vs stayers\n",
    "                leavers_values = sample_df[feature][leavers_mask]\n",
    "                stayers_values = sample_df[feature][stayers_mask]\n",
    "                feature_analysis[feature] = {\n",
    "                    \"leavers_avg\": round(leavers_values.mean(), 1),\n",
    "                    \"stayers_avg\": round(stayers_values.mean(), 1),\n",
    "                    \"difference\": round(leavers_values.mean() - stayers_values.mean(), 1)\n",
    "                }\n",
    "    \n",
    "    # Create strategic prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a senior HR analytics consultant. Analyze this employee attrition data for strategic insights.\n",
    "    \n",
    "    OVERVIEW:\n",
    "    - 249 employees analyzed\n",
    "    - 16.1% overall attrition rate\n",
    "    - 34 high-risk employees identified\n",
    "    \n",
    "    KEY FEATURE ANALYSIS:\n",
    "    {json.dumps(feature_analysis, indent=2)}\n",
    "    \n",
    "    Provide strategic analysis including:\n",
    "    1. Primary attrition drivers and root causes\n",
    "    2. High-risk employee segments\n",
    "    3. Department/role patterns\n",
    "    4. Prioritized recommendations\n",
    "    5. Specific interventions\n",
    "    \n",
    "    Write as executive summary (300 words max).\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=400,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"Generating strategic analysis...\")\n",
    "strategic_analysis = generate_strategic_attrition_analysis()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGIC ATTRITION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(strategic_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5126e25a",
   "metadata": {},
   "source": [
    "## 7. Key Learnings & Portfolio Value\n",
    "\n",
    "### Technical Demonstration\n",
    "This project successfully integrates traditional ML with modern LLM capabilities, showing proficiency in:\n",
    "- API integration and prompt engineering\n",
    "- Hybrid analytics approaches (predictive + explanatory)\n",
    "- Sampling methodology and bias detection\n",
    "\n",
    "### Critical Insight\n",
    "The initial sampling approach revealed the importance of multi-variable stratification when working with heterogeneous populations. Correcting this bias aligned results with comprehensive analysis findings.\n",
    "\n",
    "### Business Value\n",
    "While LLMs add interpretability to ML predictions, human analytical judgment remains essential for methodology validation and strategic insight generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
